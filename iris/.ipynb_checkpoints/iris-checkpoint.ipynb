{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2eb2553-4da3-4c51-92d5-7002f604316a",
   "metadata": {},
   "source": [
    "# Test of pytorch with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9864226-2dd8-40f3-ab8c-20d37a1bc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd808763-542e-4c1c-bb33-234a4bb744e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24603bdd-3fe0-4780-a9fa-21eb084d316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    " dev = \"cuda:0\" \n",
    "else: \n",
    " dev = \"cpu\" \n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9303e68-6005-4ffa-b67e-ff10a660fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf016b7-e945-44c3-970c-0c068e6056da",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "## Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e4f807-5af5-43d6-96a1-463de2ab7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 12.,  43.,  25.,   1., 532.,  25.,   3.,   5.,  12.,   4.,  24.,  32.,\n",
      "         41.], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([12,43,25,1,532,25,3,5,12,4,24,32,41])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bd25f4-66be-4f43-a789-b25c0a1b187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefd8f6-d768-4a81-ae61-8fe0fc8d8986",
   "metadata": {},
   "source": [
    "## Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8af4997-4da5-4483-9ea1-fc26cb0ea11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yash\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbb999f-bbe9-4649-a687-4034554bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(boston.data).to(device)\n",
    "target = torch.from_numpy(boston.target).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b594fab3-bce1-46fd-a89a-65c71be0d8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4585da-5191-4c92-9775-6cad2a3632f4",
   "metadata": {},
   "source": [
    "# Creating a basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad4b73e-162f-4d83-963c-7b19ab105c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston.data,columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7bc1f00-f4ae-4365-a849-e16f39cd5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5f088c-7b9f-4cd2-9c08-216e1374b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 13\n",
    "n_h =5\n",
    "n_out  = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366eeec9-35a1-4a04-af6d-eaf248734e44",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3df0dd-3b47-4f19-ab90-9d2b93e665ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in,n_h),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h,n_h*4),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h*4,n_h*2),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h*2,n_h),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h,n_h),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h,n_out),\n",
    "                      nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c483d950-232b-413a-8842-763a9fd31af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = nn.MSELoss()\n",
    "\n",
    "optimiser = torch.optim.SGD(model.parameters() , lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc55c10-ba2f-4fe3-8d0f-03c021e9086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5000 [00:00<?, ?it/s]C:\\Users\\yash\\anaconda3\\lib\\site-packages\\torch\\utils\\_device.py:62: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return func(*args, **kwargs)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:30<00:00, 162.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.time()-start = 30.83999729156494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "epochs = 5000\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    y_pred = model(data)\n",
    "    loss = lossfn(y_pred ,target)\n",
    "    # print(f\"{epoch = } , {loss.item() = }  \",end=\"\\r\")\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimiser.step()\n",
    "\n",
    "print(f\"{time.time()-start = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d3f04-ae38-4fc1-a7d5-bc1b5812fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dac3af-e8c5-4a71-b80b-0dc7709f26a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
